{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Base Classification\n",
    "\n",
    "## Load imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make common scripts visible and knowledge base classifier code\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "sys.path.append('../kb-classifier/')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from loader import load_preprocessed_data\n",
    "from kb_classifier import KnowledgeBasePredictor\n",
    "from kb_common import wiki_topics_to_index\n",
    "from lookup_tables import topic_to_int, int_to_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the already lowercased, lemmatised data\n",
    "train_x, train_y = load_preprocessed_data('data/ohsumed_lemmatized_train.csv')\n",
    "test_x, test_y = load_preprocessed_data('data/ohsumed_lemmatized_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise and tune class probabilities for knowledge base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "kb_predictor = KnowledgeBasePredictor(topic_to_int.keys(),\n",
    "                                      topic_depth='all',\n",
    "                                      top_level_prediction_number=len(wiki_topics_to_index.keys()))\n",
    "kb_predictor.train(train_x[:100], train_y[:100], balanced_classes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess knowledge base classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Making predictions for {} documents'.format(len(test_y)))\n",
    "predict_y = kb_predictor.predict(test_x)\n",
    "classification_report, confusion_matrix = kb_predictor.get_classification_report(test_y, predict_y)\n",
    "\n",
    "print(classification_report)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find examples where predictions went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "for topic, index in topic_to_int.items():    \n",
    "    topic_subset = predict_y[test_y == index]    \n",
    "    topic_subset_incorrect = topic_subset[topic_subset != index]\n",
    "    document_subset = test_x[test_y == index]\n",
    "    document_subset = document_subset[topic_subset != index]\n",
    "    \n",
    "    if len(document_subset) > 0:\n",
    "        print('------ 5 random erroneous predictions for {} ------'.format(topic))\n",
    "        print('')\n",
    "        random_indices = np.random.choice(np.arange(len(topic_subset_incorrect)), 5)\n",
    "        for index in random_indices:\n",
    "            print(document_subset[index])\n",
    "            print('')\n",
    "            print('Above classified as {}'.format(int_to_topic[topic_subset_incorrect[index]]))\n",
    "            print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
