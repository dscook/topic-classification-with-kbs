{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Classification\n",
    "\n",
    "## Load imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make common scripts visible and unsupervised classifier code\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "sys.path.append('../kb-classifier/')\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from reuters_parser import load_data\n",
    "from lookup_tables import topic_code_to_topic_dict, topic_code_to_int\n",
    "from sentence_utils import remove_stop_words_and_lemmatize\n",
    "from conversion import convert_dictionary_to_array\n",
    "from classifier_runner import run_unsupervised_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitise_each_topic(dataset):\n",
    "    \"\"\"\n",
    "    We only need to remove stop words.\n",
    "    \"\"\"\n",
    "    data_sanitised = defaultdict(list)\n",
    "    \n",
    "    for topic_code, articles in dataset.items():\n",
    "        for article in articles:\n",
    "            article_sanitised = remove_stop_words_and_lemmatize(article, lowercase=False, lemmatize=False)\n",
    "            data_sanitised[topic_code].append(article_sanitised)\n",
    "    \n",
    "    return data_sanitised\n",
    "\n",
    "#year_data = load_data('19960820', '19970819', '../../../downloads/reuters/rcv1/', topic_code_to_topic_dict)\n",
    "year_data = load_data('19960820', '19960830', '../../../downloads/reuters/rcv1/', topic_code_to_topic_dict)\n",
    "\n",
    "year_data_sanitised = sanitise_each_topic(year_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accurate comparison with the Naive Bayes classifier, keep the last 20% of documents using the same random seed.  I.e. we are making predictions on the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for 533 documents\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Split data into 80% train, 20% test\n",
    "x, y = convert_dictionary_to_array(year_data_sanitised, topic_code_to_int)\n",
    "total_examples = len(y)\n",
    "split_point = int(total_examples * 0.8)\n",
    "test_x = x[split_point:]\n",
    "test_y = y[split_point:]\n",
    "\n",
    "print('Making predictions for {} documents'.format(len(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess unsupervised classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eb2da1b318dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                      \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                      \u001b[0mtopic_code_to_topic_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                      wiki_topics_to_actual_topics)\n\u001b[0m",
      "\u001b[0;32m~/Development/university/Project/code/topic-classification-with-kbs/kb-classifier/classifier_runner.py\u001b[0m in \u001b[0;36mrun_unsupervised_classifier\u001b[0;34m(test_x, test_y, topic_labels, wiki_topics_to_actual_topics)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtopic_index_to_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_indexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtopic_index_to_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwiki_topics_to_actual_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtopic_to_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Determine the most prominent topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "wiki_topics_to_actual_topics = {\n",
    "    'Crime': 0,\n",
    "    'Law': 0,\n",
    "    'Business': 1,\n",
    "    'Economics': 1,\n",
    "    'Elections': 2,\n",
    "    'Politics': 2,\n",
    "    'Health': 3,\n",
    "    'Medicine': 3,\n",
    "    'Religion': 4,\n",
    "    'Theology': 4,\n",
    "    'Sports': 5\n",
    "}\n",
    "\n",
    "report = run_unsupervised_classifier(test_x,\n",
    "                                     test_y, \n",
    "                                     topic_code_to_topic_dict.values(),\n",
    "                                     wiki_topics_to_actual_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1,2,1,3,4,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
