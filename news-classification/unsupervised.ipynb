{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Classification\n",
    "\n",
    "## Load imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make common scripts visible and unsupervised classifier code\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "sys.path.append('../kb-classifier/')\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from reuters_parser import load_data\n",
    "from lookup_tables import topic_code_to_topic_dict, topic_code_to_int, int_to_topic_code\n",
    "from sentence_utils import remove_stop_words_and_lemmatize\n",
    "from conversion import convert_dictionary_to_array\n",
    "from kb_classifier import KnowledgeBasePredictor\n",
    "from kb_common import int_to_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitise_each_topic(text):      \n",
    "    return remove_stop_words_and_lemmatize(text, lowercase=False, lemmatize=False, keep_nouns_only=True)\n",
    "\n",
    "\n",
    "year_data = load_data('19960820', '19970819', '../../../downloads/reuters/rcv1/', topic_code_to_topic_dict)\n",
    "#year_data = load_data('19960820', '19960830', '../../../downloads/reuters/rcv1/', topic_code_to_topic_dict)\n",
    "\n",
    "# For accurate comparison with the Naive Bayes classifier, keep the last 20% of documents using the same random seed.\n",
    "# I.e. we are making predictions on the same test set.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get 20% test\n",
    "x, y = convert_dictionary_to_array(year_data, topic_code_to_int)\n",
    "total_examples = len(y)\n",
    "split_point = int(total_examples * 0.8)\n",
    "test_x = np.array(list(map(sanitise_each_topic, x[split_point:])))\n",
    "test_y = y[split_point:]\n",
    "\n",
    "\n",
    "# Take 20 documents of each type from the training set for classifier tuning\n",
    "train_x = []\n",
    "train_y = np.zeros(shape=7200)\n",
    "\n",
    "counts = np.zeros(shape=len(topic_code_to_int.keys()))\n",
    "current_index = 0\n",
    "print(split_point)\n",
    "for i in range(split_point):\n",
    "    topic_int = y[i]\n",
    "    \n",
    "    if counts[topic_int] < 1200:\n",
    "        train_x.append(x[i])\n",
    "        train_y[current_index] = topic_int\n",
    "        counts[topic_int] += 1\n",
    "        current_index += 1\n",
    "\n",
    "train_x = np.array(list(map(sanitise_each_topic, train_x)))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise and tune class probabilities for unsupervised learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "kb_predictor = KnowledgeBasePredictor(topic_code_to_topic_dict.values(), topic_depth=1)\n",
    "kb_predictor.train(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = kb_predictor.predict(train_x)\n",
    "classification_report, confusion_matrix = kb_predictor.get_classification_report(train_y, predict_y)\n",
    "\n",
    "print(classification_report)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_means = np.zeros(shape=(6, 6))\n",
    "\n",
    "# Plot graph of mean topic probabilities for each topic class\n",
    "for index, topic_code in int_to_topic_code.items():\n",
    "    prob_mean = np.mean(kb_predictor.last_class_probabilities[train_y == index], axis=0)\n",
    "    prob_std = np.std(kb_predictor.last_class_probabilities[train_y == index], axis=0)\n",
    "    prob_means[index] = prob_mean\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Mean Topic Probabilies for {} Articles'.format(topic_code_to_topic_dict[topic_code]))\n",
    "    plt.xlabel('Probability')\n",
    "    plt.xlim(0.0, 0.53)\n",
    "    sns.barplot(x=prob_mean, y=list(int_to_topic.values()))\n",
    "    plt.savefig('topic_prob_{}.pdf'.format(topic_code_to_topic_dict[topic_code]), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "# Plot graph of mean topic probabilities for each topic class\n",
    "for index, topic_code in int_to_topic_code.items():\n",
    "    prob_mean = np.mean(kb_predictor.last_class_probabilities[train_y == index], axis=0)\n",
    "    prob_std = np.std(kb_predictor.last_class_probabilities[train_y == index], axis=0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Standardised Value for {} Articles'.format(topic_code_to_topic_dict[topic_code]))\n",
    "    plt.xlabel('Standardised Value')\n",
    "    plt.xlim(-2.5, 2.5)\n",
    "    sns.barplot(x=((prob_mean-np.mean(prob_means, axis=0))/np.std(prob_means, axis=0)),\n",
    "                   y=list(int_to_topic.values()))\n",
    "    plt.savefig('standardised_{}.pdf'.format(topic_code_to_topic_dict[topic_code]), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess unsupervised classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Making predictions for {} documents'.format(len(test_y)))\n",
    "predict_y = kb_predictor.predict(test_x)\n",
    "classification_report, confusion_matrix = kb_predictor.get_classification_report(test_y, predict_y)\n",
    "\n",
    "print(classification_report)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find examples where predictions went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_code, index in topic_code_to_int.items():\n",
    "    topic_subset = predict_y[test_y == index]\n",
    "    topic_subset_incorrect = topic_subset[topic_subset != index]\n",
    "    document_subset = test_x[test_y == index]\n",
    "    document_subset = document_subset[topic_subset != index]\n",
    "    \n",
    "    print('------ 5 random erroneous predictions for {} ------'.format(topic_code_to_topic_dict[topic_code]))\n",
    "    print('')\n",
    "    random_indices = np.random.choice(np.arange(len(topic_subset_incorrect)), 5)\n",
    "    for index in random_indices:\n",
    "        print(document_subset[index])\n",
    "        print('')\n",
    "        print('Above classified as {}'.format(topic_code_to_topic_dict[int_to_topic_code[topic_subset_incorrect[index]]]))\n",
    "        print('')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
