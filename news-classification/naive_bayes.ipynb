{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "## Load imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make common scripts visible\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "\n",
    "from loader import load_preprocessed_data\n",
    "from classification import run_bernoulli_naive_bayes, run_multinomial_naive_bayes, run_multinomial_naive_bayes_tfidf\n",
    "from lookup_tables import topic_code_to_topic_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use already lemmatized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2091\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed_data('data/rcv1_lemmatized_reduced.csv')\n",
    "\n",
    "# Split data into 80% train, 20% test\n",
    "total_examples = len(y)\n",
    "split_point = int(total_examples * 0.8)\n",
    "train_x = x[:split_point]\n",
    "train_y = y[:split_point]\n",
    "test_x = x[split_point:]\n",
    "test_y = y[split_point:]\n",
    "\n",
    "print('Number of training examples: {}'.format(len(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Bernoulli Naive Bayes baseline classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Bernoulli Naive Bayes and report classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "CRIME, LAW ENFORCEMENT   0.708812  0.968586  0.818584       191\n",
      "  ECONOMIC PERFORMANCE   0.954545  0.724138  0.823529        58\n",
      "             ELECTIONS   0.775000  0.563636  0.652632        55\n",
      "                HEALTH   1.000000  0.250000  0.400000        36\n",
      "              RELIGION   1.000000  0.272727  0.428571        11\n",
      "                SPORTS   1.000000  0.965116  0.982249       172\n",
      "\n",
      "             micro avg   0.833652  0.833652  0.833652       523\n",
      "             macro avg   0.906393  0.624034  0.684261       523\n",
      "          weighted avg   0.864956  0.833652  0.818490       523\n",
      "\n",
      "[[185   0   6   0   0   0]\n",
      " [ 15  42   1   0   0   0]\n",
      " [ 22   2  31   0   0   0]\n",
      " [ 25   0   2   9   0   0]\n",
      " [  8   0   0   0   3   0]\n",
      " [  6   0   0   0   0 166]]\n"
     ]
    }
   ],
   "source": [
    "predict_y = run_bernoulli_naive_bayes(train_x,\n",
    "                                      train_y,\n",
    "                                      test_x,\n",
    "                                      test_y,\n",
    "                                      ngram_range = (1, 1))\n",
    "print(classification_report(test_y, predict_y, digits=6, target_names=topic_code_to_topic_dict.values()))\n",
    "print(confusion_matrix(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "CRIME, LAW ENFORCEMENT   0.514825  1.000000  0.679715       191\n",
      "  ECONOMIC PERFORMANCE   1.000000  0.034483  0.066667        58\n",
      "             ELECTIONS   1.000000  0.109091  0.196721        55\n",
      "                HEALTH   0.000000  0.000000  0.000000        36\n",
      "              RELIGION   0.000000  0.000000  0.000000        11\n",
      "                SPORTS   1.000000  0.837209  0.911392       172\n",
      "\n",
      "             micro avg   0.655832  0.655832  0.655832       523\n",
      "             macro avg   0.585804  0.330130  0.309083       523\n",
      "          weighted avg   0.732947  0.655832  0.576045       523\n",
      "\n",
      "[[191   0   0   0   0   0]\n",
      " [ 56   2   0   0   0   0]\n",
      " [ 49   0   6   0   0   0]\n",
      " [ 36   0   0   0   0   0]\n",
      " [ 11   0   0   0   0   0]\n",
      " [ 28   0   0   0   0 144]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict_y = run_bernoulli_naive_bayes(train_x,\n",
    "                                      train_y,\n",
    "                                      test_x,\n",
    "                                      test_y,\n",
    "                                      ngram_range = (1, 2))\n",
    "print(classification_report(test_y, predict_y, digits=6, target_names=topic_code_to_topic_dict.values()))\n",
    "print(confusion_matrix(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Multinomial Naive Bayes performance using term counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "CRIME, LAW ENFORCEMENT   0.943299  0.958115  0.950649       191\n",
      "  ECONOMIC PERFORMANCE   0.933333  0.965517  0.949153        58\n",
      "             ELECTIONS   0.777778  0.890909  0.830508        55\n",
      "                HEALTH   1.000000  0.777778  0.875000        36\n",
      "              RELIGION   1.000000  0.818182  0.900000        11\n",
      "                SPORTS   1.000000  0.982558  0.991202       172\n",
      "\n",
      "             micro avg   0.944551  0.944551  0.944551       523\n",
      "             macro avg   0.942402  0.898843  0.916085       523\n",
      "          weighted avg   0.948530  0.944551  0.944913       523\n",
      "\n",
      "[[183   0   8   0   0   0]\n",
      " [  1  56   1   0   0   0]\n",
      " [  2   4  49   0   0   0]\n",
      " [  3   0   5  28   0   0]\n",
      " [  2   0   0   0   9   0]\n",
      " [  3   0   0   0   0 169]]\n"
     ]
    }
   ],
   "source": [
    "predict_y = run_multinomial_naive_bayes(train_x,\n",
    "                                        train_y,\n",
    "                                        test_x,\n",
    "                                        ngram_range = (1, 1))\n",
    "print(classification_report(test_y, predict_y, digits=6, target_names=topic_code_to_topic_dict.values()))\n",
    "print(confusion_matrix(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "CRIME, LAW ENFORCEMENT   0.874419  0.984293  0.926108       191\n",
      "  ECONOMIC PERFORMANCE   0.963636  0.913793  0.938053        58\n",
      "             ELECTIONS   0.894737  0.927273  0.910714        55\n",
      "                HEALTH   1.000000  0.583333  0.736842        36\n",
      "              RELIGION   1.000000  0.727273  0.842105        11\n",
      "                SPORTS   1.000000  0.970930  0.985251       172\n",
      "\n",
      "             micro avg   0.933078  0.933078  0.933078       523\n",
      "             macro avg   0.955465  0.851149  0.889846       523\n",
      "          weighted avg   0.939035  0.933078  0.930470       523\n",
      "\n",
      "[[188   0   3   0   0   0]\n",
      " [  4  53   1   0   0   0]\n",
      " [  2   2  51   0   0   0]\n",
      " [ 13   0   2  21   0   0]\n",
      " [  3   0   0   0   8   0]\n",
      " [  5   0   0   0   0 167]]\n"
     ]
    }
   ],
   "source": [
    "predict_y = run_multinomial_naive_bayes(train_x,\n",
    "                                        train_y,\n",
    "                                        test_x,\n",
    "                                        ngram_range = (1, 2))\n",
    "print(classification_report(test_y, predict_y, digits=6, target_names=topic_code_to_topic_dict.values()))\n",
    "print(confusion_matrix(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Multinomial Naive Bayes performance using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "CRIME, LAW ENFORCEMENT   0.692029  1.000000  0.817987       191\n",
      "  ECONOMIC PERFORMANCE   0.979592  0.827586  0.897196        58\n",
      "             ELECTIONS   0.967742  0.545455  0.697674        55\n",
      "                HEALTH   0.000000  0.000000  0.000000        36\n",
      "              RELIGION   0.000000  0.000000  0.000000        11\n",
      "                SPORTS   1.000000  0.970930  0.985251       172\n",
      "\n",
      "             micro avg   0.833652  0.833652  0.833652       523\n",
      "             macro avg   0.606560  0.557328  0.566351       523\n",
      "          weighted avg   0.792007  0.833652  0.795618       523\n",
      "\n",
      "[[191   0   0   0   0   0]\n",
      " [  9  48   1   0   0   0]\n",
      " [ 24   1  30   0   0   0]\n",
      " [ 36   0   0   0   0   0]\n",
      " [ 11   0   0   0   0   0]\n",
      " [  5   0   0   0   0 167]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict_y = run_multinomial_naive_bayes_tfidf(train_x,\n",
    "                                              train_y,\n",
    "                                              test_x,\n",
    "                                              ngram_range = (1, 1))\n",
    "print(classification_report(test_y, predict_y, digits=6, target_names=topic_code_to_topic_dict.values()))\n",
    "print(confusion_matrix(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "CRIME, LAW ENFORCEMENT   0.636667  1.000000  0.778004       191\n",
      "  ECONOMIC PERFORMANCE   1.000000  0.620690  0.765957        58\n",
      "             ELECTIONS   0.958333  0.418182  0.582278        55\n",
      "                HEALTH   0.000000  0.000000  0.000000        36\n",
      "              RELIGION   0.000000  0.000000  0.000000        11\n",
      "                SPORTS   1.000000  0.947674  0.973134       172\n",
      "\n",
      "             micro avg   0.789675  0.789675  0.789675       523\n",
      "             macro avg   0.599167  0.497758  0.516562       523\n",
      "          weighted avg   0.773062  0.789675  0.750342       523\n",
      "\n",
      "[[191   0   0   0   0   0]\n",
      " [ 21  36   1   0   0   0]\n",
      " [ 32   0  23   0   0   0]\n",
      " [ 36   0   0   0   0   0]\n",
      " [ 11   0   0   0   0   0]\n",
      " [  9   0   0   0   0 163]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict_y = run_multinomial_naive_bayes_tfidf(train_x,\n",
    "                                              train_y,\n",
    "                                              test_x,\n",
    "                                              ngram_range = (1, 2))\n",
    "print(classification_report(test_y, predict_y, digits=6, target_names=topic_code_to_topic_dict.values()))\n",
    "print(confusion_matrix(test_y, predict_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
