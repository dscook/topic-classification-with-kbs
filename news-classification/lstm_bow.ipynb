{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Bag of Words Investigation\n",
    "\n",
    "## Load imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Make common scripts visible\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "from loader import load_preprocessed_data\n",
    "from word_embeddings import DocToIntSequenceConverter\n",
    "from lstm import LstmPredictor\n",
    "from lookup_tables import int_to_topic_code, topic_code_to_topic_dict, topic_code_to_int\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6000\n",
      "Number of validation examples: 18122\n",
      "Number of test examples: 18122\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed_data('data/rcv1_lemmatized.csv')\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split data into 60% train, 20% validation, 20% test\n",
    "total_examples = len(y)\n",
    "\n",
    "split_point_1 = int(total_examples * 0.6)\n",
    "split_point_2 = int(total_examples * 0.8)\n",
    "\n",
    "train_x = x[:6000]\n",
    "train_y = y[:6000]\n",
    "\n",
    "val_x = x[split_point_1:split_point_2]\n",
    "val_y = y[split_point_1:split_point_2]\n",
    "\n",
    "test_x = x[split_point_2:]\n",
    "test_y = y[split_point_2:]\n",
    "\n",
    "print('Number of training examples: {}'.format(len(train_x)))\n",
    "print('Number of validation examples: {}'.format(len(val_x)))\n",
    "print('Number of test examples: {}'.format(len(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of article in words: 6\n",
      "Maximum length of article in words: 1697\n",
      "Mean length of article in words: 165.0182\n",
      "St dev of length of article in words: 112.3258\n",
      "Percentage of articles exceeding max sequence length limit: 0.6167%\n"
     ]
    }
   ],
   "source": [
    "# Find the length of a tweet in words\n",
    "article_lengths = np.array([len(article.split()) for article in train_x])\n",
    "\n",
    "print('Minimum length of article in words: {}'.format(np.min(article_lengths)))\n",
    "print('Maximum length of article in words: {}'.format(np.max(article_lengths)))\n",
    "print('Mean length of article in words: {:.4f}'.format(np.mean(article_lengths)))\n",
    "print('St dev of length of article in words: {:.4f}'.format(np.std(article_lengths)))\n",
    "\n",
    "# Set the max sequence length to mean plus 3 standard deviations (99.7% confidence)\n",
    "max_sequence_length = int(np.mean(article_lengths) + np.std(article_lengths)*3)\n",
    "\n",
    "# Confirm not many tweets exceed this limit\n",
    "articles_exceeding_limit = [article for article in train_x if len(article.split()) > max_sequence_length]\n",
    "percentage_articles_exceeding_limit = (len(articles_exceeding_limit)/len(train_x))*100\n",
    "print('Percentage of articles exceeding max sequence length limit: {:.4f}%'.format(percentage_articles_exceeding_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert articles to sequence of integers representing the words\n",
    "article_to_int_seq_converter = DocToIntSequenceConverter(train_x, max_sequence_length)\n",
    "train_x_seq = article_to_int_seq_converter.convert_to_integer_sequences(train_x)\n",
    "val_x_seq = article_to_int_seq_converter.convert_to_integer_sequences(val_x)\n",
    "test_x_seq = article_to_int_seq_converter.convert_to_integer_sequences(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LSTM and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word embedding model\n",
    "class EmbeddingModel:\n",
    "    \n",
    "    def __init__(self, train_x):\n",
    "        self.vectoriser = CountVectorizer(lowercase = False, binary = True, ngram_range = (1,1))\n",
    "        self.vectoriser.fit(train_x)\n",
    "        \n",
    "    def get_vector(self, word):\n",
    "        return self.vectoriser.transform([word]).toarray()[0]\n",
    "    \n",
    "    def get_embedding_dim(self):\n",
    "        return self.vectoriser.transform(['']).shape[1]\n",
    "\n",
    "embedding_model = EmbeddingModel(train_x)\n",
    "word_embedding_dim = embedding_model.get_embedding_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 18122 samples\n",
      "Epoch 1/20\n",
      "5984/6000 [============================>.] - ETA: 6s - loss: 1.3898 - acc: 0.4236 "
     ]
    }
   ],
   "source": [
    "lstm = LstmPredictor(article_to_int_seq_converter.get_word_index(),\n",
    "                     word_embedding_dim,\n",
    "                     max_sequence_length,\n",
    "                     embedding_model,\n",
    "                     len(int_to_topic_code.values()))\n",
    "lstm.train(train_x_seq, train_y, val_x_seq, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and report classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialise the LSTM, will use weights from the previous training run.\n",
    "lstm = LstmPredictor(article_to_int_seq_converter.get_word_index(),\n",
    "                     word_embedding_dim,\n",
    "                     max_sequence_length,\n",
    "                     embedding_model,\n",
    "                     len(int_to_topic_code.values()),\n",
    "                     use_saved_weights=True)\n",
    "test_y_predict = lstm.predict(test_x_seq)\n",
    "print(classification_report(test_y, test_y_predict, digits=6, target_names=topic_code_to_topic_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find examples where predictions went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_code, index in topic_code_to_int.items():\n",
    "    topic_subset = test_y_predict[test_y == index]\n",
    "    topic_subset_incorrect = topic_subset[topic_subset != index]\n",
    "    document_subset = test_x[test_y == index]\n",
    "    document_subset = document_subset[topic_subset != index]\n",
    "    \n",
    "    print('------ 5 random erroneous predictions for {} ------'.format(topic_code_to_topic_dict[topic_code]))\n",
    "    print('')\n",
    "    random_indices = np.random.choice(np.arange(len(topic_subset_incorrect)), 5)\n",
    "    for index in random_indices:\n",
    "        print(document_subset[index])\n",
    "        print('')\n",
    "        print('Above classified as {}'.format(topic_code_to_topic_dict[int_to_topic_code[topic_subset_incorrect[index]]]))\n",
    "        print('')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
