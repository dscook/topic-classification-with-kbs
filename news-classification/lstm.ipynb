{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "## Load imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Make common scripts visible\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "from loader import load_preprocessed_data\n",
    "from word_embeddings import DocToIntSequenceConverter\n",
    "from lstm import LstmPredictor\n",
    "from lookup_tables import int_to_topic_code, topic_code_to_topic_dict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 54366\n"
     ]
    }
   ],
   "source": [
    "x, y = load_preprocessed_data('data/rcv1_no_stopwords.csv')\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split data into 60% train, 20% validation, 20% test\n",
    "total_examples = len(y)\n",
    "\n",
    "split_point_1 = int(total_examples * 0.6)\n",
    "split_point_2 = int(total_examples * 0.8)\n",
    "\n",
    "train_x = x[:split_point_1]\n",
    "train_y = y[:split_point_1]\n",
    "\n",
    "val_x = x[split_point_1:split_point_2]\n",
    "val_y = y[split_point_1:split_point_2]\n",
    "\n",
    "test_x = x[split_point_2:]\n",
    "test_y = y[split_point_2:]\n",
    "\n",
    "print('Number of training examples: {}'.format(len(train_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of article in words: 3\n",
      "Maximum length of article in words: 2392\n",
      "Mean length of article in words: 109.1119\n",
      "St dev of length of article in words: 76.5720\n",
      "Percentage of articles exceeding max sequence length limit: 0.5831%\n"
     ]
    }
   ],
   "source": [
    "# Find the length of a tweet in words\n",
    "article_lengths = np.array([len(article.split()) for article in train_x])\n",
    "\n",
    "print('Minimum length of article in words: {}'.format(np.min(article_lengths)))\n",
    "print('Maximum length of article in words: {}'.format(np.max(article_lengths)))\n",
    "print('Mean length of article in words: {:.4f}'.format(np.mean(article_lengths)))\n",
    "print('St dev of length of article in words: {:.4f}'.format(np.std(article_lengths)))\n",
    "\n",
    "# Set the max sequence length to mean plus 3 standard deviations (99.7% confidence)\n",
    "max_sequence_length = int(np.mean(article_lengths) + np.std(article_lengths)*3)\n",
    "\n",
    "# Confirm not many tweets exceed this limit\n",
    "articles_exceeding_limit = [article for article in train_x if len(article.split()) > max_sequence_length]\n",
    "percentage_articles_exceeding_limit = (len(articles_exceeding_limit)/len(train_x))*100\n",
    "print('Percentage of articles exceeding max sequence length limit: {:.4f}%'.format(percentage_articles_exceeding_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert articles to sequence of integers representing the words\n",
    "article_to_int_seq_converter = DocToIntSequenceConverter(train_x, max_sequence_length)\n",
    "train_x_seq = article_to_int_seq_converter.convert_to_integer_sequences(train_x)\n",
    "val_x_seq = article_to_int_seq_converter.convert_to_integer_sequences(val_x)\n",
    "test_x_seq = article_to_int_seq_converter.convert_to_integer_sequences(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LSTM and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dim = 300\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('../tweet-classification/embeddings/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54366 samples, validate on 18122 samples\n",
      "Epoch 1/20\n",
      "54366/54366 [==============================] - 1581s 29ms/step - loss: 0.3308 - acc: 0.9012 - val_loss: 0.2182 - val_acc: 0.9361\n",
      "Epoch 2/20\n",
      "28608/54366 [==============>...............] - ETA: 11:31 - loss: 0.2070 - acc: 0.9389"
     ]
    }
   ],
   "source": [
    "lstm = LstmPredictor(article_to_int_seq_converter.get_word_index(),\n",
    "                     word_embedding_dim,\n",
    "                     max_sequence_length,\n",
    "                     word2vec_model,\n",
    "                     len(int_to_topic_code.values()))\n",
    "lstm.train(train_x_seq, train_y, val_x_seq, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and report classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialise the LSTM, will use weights from the previous training run.\n",
    "lstm = LstmPredictor(article_to_int_seq_converter.get_word_index(),\n",
    "                     word_embedding_dim,\n",
    "                     max_sequence_length,\n",
    "                     word2vec_model,\n",
    "                     len(int_to_topic_code.values()),\n",
    "                     use_saved_weights=True)\n",
    "test_y_predict = lstm.predict(test_x_seq)\n",
    "print(classification_report(test_y, test_y_predict, digits=6, target_names=topic_code_to_topic_dict.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
